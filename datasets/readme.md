# Datasets

You can quickly download any of these datasets with the datasets.py script. This uses fuzzy search to figure out what dataset you are trying to find. An exhaustive list of all the audio, text, image, and video datasets are listed below.

Note you can search for more datasets using Google DataSet search @ https://toolbox.google.com/datasetsearch or Kaggle @ https://www.kaggle.com/datasets.

You can always create datasets with [mTurk](https://towardsdatascience.com/how-i-created-a-40-000-labeled-audio-dataset-in-4-hours-of-work-and-500-17ad9951b180) and/or [SurveyLex](https://surveylex.com) as well.

## Audio datasets 

Lots of audio datasets on here. https://towardsdatascience.com/a-data-lakes-worth-of-audio-datasets-b45b88cd4ad

### Open source 
* [AudioSet](https://research.google.com/audioset/) - A large-scale dataset of manually annotated audio events
* [Common Voice](https://voice.mozilla.org/) - Common Voice is Mozilla's initiative to help teach machines how real people speak
* [LJ speech](https://keithito.com/LJ-Speech-Dataset/) - This is a public domain speech dataset consisting of 13,100 short audio clips of a single speaker reading passages from 7 non-fiction books. A transcription is provided for each clip. Clips vary in length from 1 to 10 seconds and have a total length of approximately 24 hours.
* [CMU Wilderness](http://festvox.org/cmu_wilderness/) - (noncommercial) - not available but a great one. 
* [Urban Sound Dataset](https://urbansounddataset.weebly.com/) - two datasets and a taxonomy for urban sound research.
* [Noisy dataset](https://datashare.is.ed.ac.uk/handle/10283/2791)- Clean and noisy parallel speech database. The database was designed to train and test speech enhancement methods that operate at 48kHz. 
* [Spoken Commands dataset](https://github.com/JohannesBuchner/spoken-command-recognition) - A large database of free audio samples (10M words), a test bed for voice activity detection algorithms and for recognition of syllables (single-word commands).
* [Freesound dataset](https://www.kaggle.com/c/freesound-audio-tagging-2019/data) - many different sound events. https://annotator.freesound.org/ and https://annotator.freesound.org/fsd/explore/
* [Karoldvl-ESC](https://github.com/karoldvl/ESC-50) - The ESC-50 dataset is a labeled collection of 2000 environmental audio recordings suitable for benchmarking methods of environmental sound classification.
* [Librispeech](https://www.openslr.org/12) - LibriSpeech is a corpus of approximately 1000 hours of 16Khz read English speech derived from read audiobooks from the LibriVox project.
* [TedLIUM](https://www.openslr.org/51/) - The TED-LIUM corpus was made from audio talks and their transcriptions available on the TED website (noncommercial)
* [VoxForge](http://www.repository.voxforge1.org/downloads/SpeechCorpus/Trunk/) - VoxForge was set up to collect transcribed speech for use with Free and Open Source Speech Recognition Engines.
* [Tatoeba](https://tatoeba.org/eng/downloads) - Tatoeba is a large database of sentences, translations, and spoken audio for use in language learning. This download contains spoken English recorded by their community.
* [Speech accent archive](https://www.kaggle.com/rtatman/speech-accent-archive/version/1) - For various accent detection tasks.
* [The Emotional Voices Database](https://github.com/numediart/EmoV-DB) - various emotions with 5 voice actors (amused, angry, disgusted, neutral, sleepy).
* [TIMIT dataset](https://catalog.ldc.upenn.edu/LDC93S1) - Linguistic data consortium dataset for speech recogniition. Costs money and is not free, so may skip this one.

### NeuroLex datasets
* [JamesVM dataset]() - 170,000+ voicemails left for loved ones around key events like anniversaries or birthdays. 1,000 of these files are annotated. 
* [MHA dataset]() - 350 self-reported patients with voice tasks and PHQ-9 depression labels.
* [YouTube disease dataset]() - >30 people in each category using YouTube videos (audio only).
* [Voiceome dataset]() - working on creating the world's largest dataset to tie voice information to health traits.
* [Framingham Heart Study dataset]() - 200 patients with transcriptions (manual) and neuropsychological testing for Alzheimer's and other areas. 
* [UW research dataset]() - some data associated labels from research assistants collecting data with disease labels (through REDCAP). 
* [Train-emotions]() - emotion labels using deep learning models + audio. 

## Text datasets
* 

## Image datasets
* 

## Video datasets
### Open source 
* VoxCeleb - https://github.com/andabi/voice-vector
* Lip reading dataset - http://www.robots.ox.ac.uk/~vgg/data/lip_reading/

### NeuroLex datasets
* [YouTube disease dataset]() - >30 people in each category using YouTube videos (videos). 

## CSV datasets 
### Open source
* [](see pydataset)
### NeuroLex datasets
* TRIBE 4 application - test 

